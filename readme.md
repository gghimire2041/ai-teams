# ü§ñ Teams AI System

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Flask](https://img.shields.io/badge/flask-3.0+-green.svg)](https://flask.palletsprojects.com/)
[![LM Studio](https://img.shields.io/badge/LM%20Studio-Local%20AI-brightgreen.svg)](https://lmstudio.ai/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)](https://github.com/gghimire2041/ai-teams)
[![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)](https://github.com/gghimire2041/ai-teams/releases)

> **A production-ready multi-agent AI system where specialized AI agents collaborate to develop software projects autonomously using local LM Studio inference.**

üéØ **Teams AI System** represents the next evolution of software development where AI agents work together like a real development team - writing production-quality code, creating comprehensive tests, managing deployments, and generating professional documentation automatically using locally hosted AI models.

‚ú® **Now with full JSON serialization support, enhanced agent management, and production-ready stability!**

## üéØ Key Features

### üöÄ **Multi-Agent Collaboration**
- **üßë‚Äçüíª Coder Agent**: Generates production-ready code with proper documentation, error handling, and security best practices
- **üß™ Tester Agent**: Creates comprehensive test suites with edge cases, mocking, and coverage analysis
- **üîß Integrator Agent**: Manages CI/CD pipelines, containerization, and deployment automation
- **üìö Documenter Agent**: Generates API docs, user guides, README files, and technical specifications
- **üë• Custom Agents**: Create specialized agents with unique names and capabilities

### üß† **Advanced AI Integration**
- **üîó LM Studio Integration**: Full support for local models with fallback responses
- **üîÑ Multi-Endpoint Support**: Automatically tries multiple API endpoints for reliability
- **‚ö° Optimized Performance**: Intelligent caching and connection pooling
- **üéõÔ∏è Configurable Parameters**: Temperature, max tokens, top-p, and model selection
- **üîí Privacy First**: All AI processing happens locally on your machine
- **üì± Offline Operation**: No internet required once models are downloaded

### üéØ **Intelligent Task Orchestration**
- **üìã Smart Assignment**: Keyword-based automatic agent selection
- **üîó Dependency Management**: Tasks wait for prerequisites to complete
- **‚öñÔ∏è Priority Queuing**: High-priority tasks get processed first
- **üîÑ Real-time Execution**: Live task processing with status updates
- **üõ°Ô∏è Error Recovery**: Graceful handling of failures with detailed logging
- **üìä Progress Tracking**: Visual dashboard showing all agent activities

### üíæ **Advanced Memory System**
- **‚ö° Short-term Memory**: Session context for ongoing conversations
- **üß† Long-term Memory**: FAISS vector database for persistent knowledge
- **üìö Episodic Memory**: Complete history of agent actions and decisions
- **üîç Semantic Search**: Find relevant past experiences automatically
- **üí° Learning Capability**: Agents improve based on past interactions

### üåê **Production-Ready Web Interface**
- **üì± Responsive Dashboard**: Works on desktop, tablet, and mobile
- **‚ö° Real-time Updates**: Live agent status and task progress
- **üé® Modern UI**: Clean, intuitive interface with beautiful styling
- **üîß Agent Management**: Create, delete, and monitor custom agents
- **üìä System Metrics**: Performance monitoring and resource usage
- **üéõÔ∏è Configuration Panel**: Easy environment and model management

### ‚ú® **Latest Enhancements (v2.0.0)**
- **üîß Fixed JSON Serialization**: Complete resolution of enum and datetime serialization issues
- **üì¶ Enhanced Database Management**: Improved SQLite operations with proper error handling
- **üöÄ Optimized Performance**: Better memory management and faster response times
- **üîí Robust Error Handling**: Comprehensive exception management throughout the system
- **üìã Agent Lifecycle Management**: Full CRUD operations for agent management
- **üéØ Task Assignment Control**: Both automatic and manual agent assignment options
- **üìä Improved Logging**: Detailed logging for debugging and monitoring
- **üîÑ Auto-recovery**: System automatically handles and recovers from common issues

## üèóÔ∏è System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Web Interface ‚îÇ    ‚îÇ Task Orchestrator‚îÇ    ‚îÇ   LM Studio     ‚îÇ
‚îÇ                 ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ                 ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   Local API     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚ñº           ‚ñº           ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ Coder Agent  ‚îÇ ‚îÇ Tester Agent ‚îÇ ‚îÇIntegrator Agt‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ           ‚îÇ           ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    Memory Manager       ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
                    ‚îÇ  ‚îÇ SQLite  ‚îÇ FAISS   ‚îÇ  ‚îÇ
                    ‚îÇ  ‚îÇDatabase ‚îÇVector DB‚îÇ  ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Quick Start

### Prerequisites

- **Python 3.8+**
- **Git** (configured with user.name and user.email)
- **LM Studio** with a compatible model loaded
- **4GB RAM** minimum (8GB+ recommended)

### LM Studio Setup

1. **Download and Install LM Studio**
   - Visit [https://lmstudio.ai/](https://lmstudio.ai/)
   - Download and install for your operating system

2. **Download a Compatible Model**
   - Recommended: Any 7B-20B parameter model (e.g., GPT-OSS-20B, Llama 2, Mistral)
   - Download through LM Studio's model browser

3. **Start LM Studio Local Server**
   - In LM Studio, go to "Local Server" tab
   - Load your chosen model
   - Click "Start Server" 
   - Verify server is running on `http://localhost:1234`

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/gghimire2041/ai-teams.git
   cd ai-teams
   ```

2. **Create and activate virtual environment**
   ```bash
   python -m venv venv
   
   # On Windows:
   venv\Scripts\activate
   
   # On macOS/Linux:
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   # Option 1: Install from requirements.txt
   pip install -r requirements.txt
   
   # Option 2: Install manually
   pip install Flask>=3.0.0 numpy>=1.24.0 faiss-cpu>=1.7.0 requests>=2.31.0
   ```

4. **Configure environment** (optional)
   ```bash
   # Set LM Studio URL if different from default
   export LM_STUDIO_URL="http://localhost:1234"
   export AI_TEMPERATURE="0.7"
   export AI_MAX_TOKENS="2048"
   
   # On Windows:
   set LM_STUDIO_URL=http://localhost:1234
   set AI_TEMPERATURE=0.7
   set AI_MAX_TOKENS=2048
   ```

### Running the System

1. **Ensure LM Studio is running** with a model loaded on `http://localhost:1234`

2. **Start the Teams AI System**:
   ```bash
   python teams_ai_system.py
   ```

3. **Expected Output**:
   ```
   üöÄ Starting Teams AI System...
   ü§ñ Connecting to LM Studio...
   ‚úÖ LM Studio connection verified
   ‚úÖ Teams AI System initialized with default agents and sample project
   üåê Web interface available at: http://localhost:8081
   ```

4. **Open your browser** and navigate to **http://localhost:8081**

## üìã Usage Guide

### Creating Projects

1. Navigate to the web dashboard
2. Fill in the "Create New Project" form:
   - **Project Name**: Descriptive name (e.g., "E-commerce API")
   - **Project Description**: Detailed requirements
3. Click "Create Project"

### Creating Tasks

Tasks are automatically assigned to appropriate agents based on keywords:

| Keywords | Agent Type | Example Task |
|----------|------------|--------------|
| code, implement, develop | **Coder** | "Implement user authentication system" |
| test, verify, validate | **Tester** | "Create unit tests for API endpoints" |
| integrate, deploy, merge | **Integrator** | "Deploy application to production" |
| document, readme, docs | **Documenter** | "Generate API documentation" |

### Creating Custom Agents

1. Use the "Create Custom Agent" form
2. Choose agent type and give it a unique name
3. The new agent will appear in your team roster
4. Assign tasks specifically to your custom agents

### Monitoring Progress

- **Agent Status**: See what each agent is currently working on
- **Task Progress**: Track completion status and outputs
- **System Metrics**: Monitor queue size and performance
- **LM Studio Status**: Verify AI model connectivity

## üîß Configuration

### Environment Variables

```bash
# LM Studio Configuration
export LM_STUDIO_URL="http://localhost:1234"    # Default LM Studio URL
export LM_STUDIO_MODEL="local-model"            # Model identifier
export LM_STUDIO_TIMEOUT="120"                  # Request timeout (seconds)

# AI Parameters
export AI_TEMPERATURE="0.7"                     # Creativity vs consistency
export AI_MAX_TOKENS="2048"                     # Maximum response length
export AI_TOP_P="0.9"                          # Nucleus sampling parameter

# System Configuration
export TEAMS_AI_PORT="8080"                     # Web interface port
export TEAMS_AI_HOST="0.0.0.0"                 # Web interface host
```

### Directory Structure

After running, the system creates:

```
teams-ai-system/
‚îú‚îÄ‚îÄ teams_ai_system.py          # Main application
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ dashboard.html          # Web interface
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ teams.db               # SQLite database
‚îÇ   ‚îú‚îÄ‚îÄ memory/                # Vector database storage
‚îÇ   ‚îî‚îÄ‚îÄ repositories/          # Generated project repositories
‚îî‚îÄ‚îÄ requirements.txt           # Python dependencies
```

## üõ†Ô∏è Troubleshooting

### Common Issues

#### LM Studio Connection Problems

**Error**: `Cannot POST /v1/chat/completions`
**Solution**: 
1. Verify LM Studio is running on `http://localhost:1234`
2. Ensure a model is loaded (not just downloaded)
3. Check that the local server is started in LM Studio

**Error**: `LM Studio API error 404`
**Solution**:
1. Test LM Studio manually: visit `http://localhost:1234` in browser
2. Verify correct port - should be 1234, not 41343 or other ports
3. Set environment variable: `export LM_STUDIO_URL="http://localhost:1234"`

#### Model Performance Issues

**Problem**: Slow AI responses
**Solution**:
- Enable GPU acceleration in LM Studio if available
- Reduce `AI_MAX_TOKENS` for shorter responses
- Use a smaller model if hardware is limited

#### Memory Issues

**Problem**: System running out of memory
**Solution**:
- Close other applications
- Use a smaller AI model
- Restart the system periodically for long sessions

### Testing LM Studio Connection

```bash
# Test if LM Studio is responding
curl http://localhost:1234/v1/models

# Test a simple completion
curl -X POST http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "local-model",
    "messages": [{"role": "user", "content": "Hello!"}],
    "temperature": 0.7,
    "max_tokens": 100
  }'
```

## üìä Example Workflows

### Web Application Development

```python
# Create project through web interface:
# Project: "Task Management App"
# Description: "Build a React/Node.js task management application"

# The system will automatically create and execute tasks like:
# 1. "Database Schema Design" ‚Üí Coder Agent
# 2. "User Authentication API" ‚Üí Coder Agent  
# 3. "Frontend Components" ‚Üí Coder Agent
# 4. "API Testing Suite" ‚Üí Tester Agent
# 5. "Integration Tests" ‚Üí Tester Agent
# 6. "Production Deployment" ‚Üí Integrator Agent
# 7. "User Documentation" ‚Üí Documenter Agent
# 8. "API Documentation" ‚Üí Documenter Agent
```

### API Development

```python
# Project: "REST API for Inventory System"
# Tasks are created with dependencies:
# 1. Database Models ‚Üí Tests for Models ‚Üí API Endpoints ‚Üí API Tests ‚Üí Documentation ‚Üí Deployment
```

## üîí Security & Privacy

### Local AI Advantages

- **Complete Privacy**: All AI processing happens locally
- **No API Keys**: No external API credentials required
- **Offline Operation**: Works without internet connection
- **Data Control**: Your code and data never leave your machine

### Security Best Practices

- Keep LM Studio updated to latest version
- Run the system in a virtual environment
- Regularly backup your projects and data
- Monitor system resources during operation

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test with different LM Studio models
5. Submit a pull request

## üìö API Reference

### REST Endpoints

```
GET  /api/status              # System and LM Studio status
GET  /api/tasks               # List all tasks
GET  /api/agents              # List all agents
GET  /api/available_agents    # Available agents for assignment
GET  /api/memory/{agent_id}   # Agent memory and learning
POST /create_project          # Create new project
POST /create_task             # Create new task
POST /create_agent            # Create custom agent
POST /delete_agent            # Remove agent
```

## üìÑ License

MIT License - see LICENSE file for details.

## üÜò Support

- **Documentation**: Read this README thoroughly
- **LM Studio Issues**: Check [LM Studio documentation](https://lmstudio.ai/)
- **GitHub Issues**: Report bugs and request features
- **Discussions**: Ask questions in GitHub Discussions

## üéØ Roadmap

- [ ] Support for more local AI platforms (Ollama, LocalAI)
- [ ] Advanced task dependency management
- [ ] Code review and approval workflows
- [ ] Plugin system for custom agent types
- [ ] Integration with popular IDEs
- [ ] Multi-project management
- [ ] Team collaboration features

---

**Ready to revolutionize your development workflow with local AI agents?**

üöÄ **Get started now and watch your AI team build amazing projects!**